{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb6c72eb-0a0c-4840-91dc-a53308e71180",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be19f8-647f-4a09-a6d2-d4aaf14f8eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import torch\n",
    "from tools import models, datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import opacus\n",
    "from tools.utils import train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8dad47-082b-4e1a-b976-e5b340be0dff",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84708bc9-2182-4493-a122-f44ffb56d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the first run download=True has to be passed to this function in order to automatically dowload the data!\n",
    "train_ds, test_ds, val_ds = datasets.Loader.load_MedNIST(sample_size=0.04, test_size=0.0872, val_size=0.125)\n",
    "train_data, train_labels = train_ds.as_tensor()\n",
    "test_data, test_labels = test_ds.as_tensor()\n",
    "val_data, val_labels = val_ds.as_tensor()\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e0f70-3420-4a65-8a42-92cfaf624a20",
   "metadata": {},
   "source": [
    "### Parameters and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1378933c-c903-4df4-a809-5d460951968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for tracking purposes\n",
    "MODEL = 'Deep2DNet'\n",
    "DATASET = 'MedNIST'\n",
    "TRACKING = True # Whether or not this run should be tracked in the results.csv\n",
    "DP = True # Whether or not Differential Privacy should be applied\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 30\n",
    "\n",
    "DELTA = 0.0001 # Set to be less then the inverse of the training dataset (from https://opacus.ai/tutorials/building_image_classifier)\n",
    "\n",
    "# Parameters for training\n",
    "length = len(train_data)\n",
    "SAMPLE_SIZE = length - length % BATCH_SIZE # NOTE: Current implementation only trains data in multiples of batch size. So BATCH_SIZE % LENGTH amount of data will not be used for training.\n",
    "SAMPLE_RATE = BATCH_SIZE / SAMPLE_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c3b58f-5d22-46e5-86ba-fd2b932bde7d",
   "metadata": {},
   "source": [
    "### Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4907abde-32fd-4b28-93f3-d3795c0f2ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(learning_rate, noise_multiplier, max_grad_norm):\n",
    "    # Getting model\n",
    "    model = models.Deep2DNet(torch)\n",
    "\n",
    "    # Setting device to train on\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    if cuda_available:\n",
    "        device = torch.device('cuda:0')\n",
    "        model.cuda(device)\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        model.cpu()\n",
    "\n",
    "    # Optimizer and Loss Function\n",
    "    params = model.parameters()\n",
    "    optim = torch.optim.Adam(params=params, lr=learning_rate)\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Setting up Differential Privacy Engine\n",
    "    if DP:\n",
    "        privacy_engine = opacus.privacy_engine.PrivacyEngine(\n",
    "            model.real_module, sample_rate=SAMPLE_RATE,\n",
    "            noise_multiplier=noise_multiplier, max_grad_norm=max_grad_norm\n",
    "        )\n",
    "        privacy_engine.attach(optim)\n",
    "    else:\n",
    "        privacy_engine = None\n",
    "\n",
    "    # Training\n",
    "    losses, test_accs, test_losses, epsilons, alphas, epoch_times = train(BATCH_SIZE, EPOCHS, DELTA,\n",
    "                                                                          model, torch,\n",
    "                                                                          optim, loss_function, \n",
    "                                                                          train_data, train_labels, \n",
    "                                                                          test_data, test_labels, \n",
    "                                                                          [1, 64, 64], device, privacy_engine)\n",
    "\n",
    "    # Validation\n",
    "    val_acc, val_loss = test(model, loss_function, torch, val_data, val_labels, device)\n",
    "\n",
    "    print(f'Validation Accuracy: {val_acc} ---- Validation Loss: {val_loss}')\n",
    "\n",
    "    # Tracking all interesting variables and results in .csv file\n",
    "    if TRACKING:\n",
    "        d = {\n",
    "            'model': MODEL,\n",
    "            'dataset': DATASET,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'epochs': EPOCHS,\n",
    "            'learning_rate': learning_rate,\n",
    "            'train_sample_size': SAMPLE_SIZE,\n",
    "            'test_sample_size': len(test_data),\n",
    "            'val_sample_size': len(val_data),\n",
    "            'delta': DELTA,\n",
    "            'noise_multiplier': noise_multiplier,\n",
    "            'max_grad_norm': max_grad_norm,\n",
    "            'dp_used': DP,\n",
    "            'epsilons': epsilons,\n",
    "            'alphas': alphas,\n",
    "            'train_losses': losses,\n",
    "            'test_accs': test_accs,\n",
    "            'test_losses': test_losses,\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'epoch_times': epoch_times\n",
    "        }      \n",
    "        df = pd.read_csv('./Results/1DS.csv')\n",
    "        df = df.append(d, ignore_index=True)\n",
    "        df.to_csv('./Results/1DS.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1f868a-b704-426b-ac3d-a5f8147be8ab",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61b78f3-e7af-47ac-9915-f6411bc56e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def gridsearch(lrs, noises, norms):\n",
    "    grid = itertools.product(lrs, noises, norms)\n",
    "    num = 0\n",
    "    \n",
    "    if DP:\n",
    "        for learning_rate, noise_multiplier, max_grad_norm in grid:\n",
    "            num += 1\n",
    "            print(f'################################# RUN No. {num} #################################')\n",
    "            run(learning_rate, noise_multiplier, max_grad_norm)\n",
    "            \n",
    "    else:\n",
    "        for learning_rate in lrs:\n",
    "            num += 1\n",
    "            print(f'################################# RUN No. {num} #################################')\n",
    "            run(learning_rate, 0 , 0)\n",
    "            \n",
    "    \n",
    "lrs = [0.0025]\n",
    "noises = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]\n",
    "norms = [5.0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
