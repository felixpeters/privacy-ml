{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b4a458-592c-4655-aad9-361965349dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import torch\n",
    "from tools import models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "sy.load('opacus')\n",
    "np.random.seed(42) # The meaning of life!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30127c81-74c2-4c22-aed8-e01b786a64e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "image/png": {
       "unconfined": true,
       "width": 400
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤  ðŸŽ¸  â™ªâ™ªâ™ª Joining Duet â™«â™«â™«  ðŸŽ»  ðŸŽ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "â™«â™«â™« > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > â¤ï¸ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at:\n",
      "â™«â™«â™« > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... \n",
      "â™«â™«â™« > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "â™«â™«â™« > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e651e4cb-754b-4498-92c5-de1b8ec55fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the pionters to the data\n",
    "time.sleep(31) # Sleep timer so you can just press restart on both notebooks without caring (might need to be adjusted)\n",
    "\n",
    "train_data_ptr = duet.store[0]\n",
    "train_labels_ptr = duet.store[1]\n",
    "\n",
    "test_data_ptr = duet.store[2]\n",
    "test_labels_ptr = duet.store[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f48c5a5-59fd-4797-97e1-8f8dd4795c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for tracking purposes\n",
    "MODEL = 'Deep2DNet'\n",
    "DATASET = 'MedNIST'\n",
    "TRACKING = True # Whether or not this run should be tracked in the results csv file\n",
    "DP = False # Whether or not Differential Privacy should be applied\n",
    "\n",
    "# Parameters for training and Differential Privacy\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.002 if DP else 0.001\n",
    "\n",
    "DELTA = 1e-4 # Set to be less then the inverse of the size of the training dataset (from https://opacus.ai/tutorials/building_image_classifier)\n",
    "NOISE_MULTIPLIER = 2.0 # The amount of noise sampled and added to the average of the gradients in a batch (from https://opacus.ai/tutorials/building_image_classifier)\n",
    "MAX_GRAD_NORM = 1.0 # The maximum L2 norm of per-sample gradients before they are aggregated by the averaging step (from https://opacus.ai/tutorials/building_image_classifier)\n",
    "\n",
    "length = len(train_data_ptr)\n",
    "SAMPLE_SIZE = length - length % BATCH_SIZE # NOTE: Current implementation only trains data in multiples of batch size. So BATCH_SIZE % LENGTH amount of data will not be used for training.\n",
    "SAMPLE_RATE = BATCH_SIZE / SAMPLE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "315d603d-da4d-4650-a06c-69411dc72724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting remote and local instances\n",
    "local_model = models.Deep2DNet(torch)\n",
    "remote_model = local_model.send(duet)\n",
    "remote_torch = duet.torch\n",
    "remote_opacus = duet.opacus\n",
    "\n",
    "# Setting device to train on\n",
    "cuda_available = remote_torch.cuda.is_available().get(request_block=True, reason='Need to check for available GPU!')\n",
    "if cuda_available:\n",
    "    device = remote_torch.device('cuda:0')\n",
    "    remote_model.cuda(device)\n",
    "else:\n",
    "    device = remote_torch.device('cpu')\n",
    "    remote_model.cpu()\n",
    "\n",
    "# Optimizer and Loss Function\n",
    "params = remote_model.parameters()\n",
    "optim = remote_torch.optim.Adam(params=params, lr=LEARNING_RATE)\n",
    "loss_function = remote_torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Setting up Differential Privacy Engine\n",
    "if DP:\n",
    "    privacy_engine_ptr = remote_opacus.privacy_engine.PrivacyEngine(\n",
    "        remote_model.real_module, sample_rate=SAMPLE_RATE,\n",
    "        noise_multiplier=NOISE_MULTIPLIER, max_grad_norm=MAX_GRAD_NORM\n",
    "    )\n",
    "    privacy_engine_ptr.to(device)\n",
    "    privacy_engine_ptr.attach(optim)\n",
    "else:\n",
    "    privacy_engine_ptr = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "983458aa-a990-4722-aba4-9ca3fc9abc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Epoch 1 ######\n",
      "Training Loss: 1.7917022705078125\n",
      "Training Loss: 1.7867822647094727\n",
      "Training Loss: 1.792954683303833\n",
      "Training Loss: 1.7914577722549438\n",
      "Training Loss: 1.7858389616012573\n",
      "Training Loss: 1.7849044799804688\n",
      "Training Loss: 1.7797846794128418\n",
      "Training Loss: 1.773114800453186\n",
      "Training Loss: 1.7783865928649902\n",
      "Training Loss: 1.758459210395813\n",
      "Training Loss: 1.7346696853637695\n",
      "Training Loss: 1.7244961261749268\n",
      "Training Loss: 1.6506494283676147\n",
      "Training Loss: 1.6024868488311768\n",
      "Training Loss: 1.590328335762024\n",
      "Training Loss: 1.6124099493026733\n",
      "Training Loss: 1.4811921119689941\n",
      "Training Loss: 1.4070463180541992\n",
      "Test Accuracy: 0.5728155374526978 ---- Test Loss: 1.3640081882476807\n",
      "Epoch time: 6.446895599365234 seconds\n",
      "###### Epoch 2 ######\n",
      "Training Loss: 1.4996532201766968\n",
      "Training Loss: 1.2566636800765991\n",
      "Training Loss: 1.2250947952270508\n",
      "Training Loss: 1.1630462408065796\n",
      "Training Loss: 1.1955317258834839\n",
      "Training Loss: 1.0501824617385864\n",
      "Training Loss: 0.9013252258300781\n",
      "Training Loss: 0.8879576921463013\n",
      "Training Loss: 0.7970130443572998\n",
      "Training Loss: 0.8163825273513794\n",
      "Training Loss: 0.7296964526176453\n",
      "Training Loss: 0.6727340221405029\n",
      "Training Loss: 0.6393997669219971\n",
      "Training Loss: 0.6064905524253845\n",
      "Training Loss: 0.5574445128440857\n",
      "Training Loss: 0.7520731091499329\n",
      "Training Loss: 0.7328668832778931\n",
      "Training Loss: 0.7303194403648376\n",
      "Test Accuracy: 0.7135922312736511 ---- Test Loss: 0.7095703482627869\n",
      "Epoch time: 5.851128578186035 seconds\n",
      "###### Epoch 3 ######\n",
      "Training Loss: 0.6287878751754761\n",
      "Training Loss: 0.6546797752380371\n",
      "Training Loss: 0.7074499726295471\n",
      "Training Loss: 0.709919810295105\n",
      "Training Loss: 0.6022234559059143\n",
      "Training Loss: 0.6850084066390991\n",
      "Training Loss: 0.5418896675109863\n",
      "Training Loss: 0.7248910665512085\n",
      "Training Loss: 0.7217854261398315\n",
      "Training Loss: 0.4664157032966614\n",
      "Training Loss: 0.6398225426673889\n",
      "Training Loss: 0.5626958608627319\n",
      "Training Loss: 0.4340922236442566\n",
      "Training Loss: 0.6606214642524719\n",
      "Training Loss: 0.5096629858016968\n",
      "Training Loss: 0.5521427392959595\n",
      "Training Loss: 0.5839856863021851\n",
      "Training Loss: 0.4903567433357239\n",
      "Test Accuracy: 0.791262149810791 ---- Test Loss: 0.5919685959815979\n",
      "Epoch time: 5.870436429977417 seconds\n",
      "###### Epoch 4 ######\n",
      "Training Loss: 0.46828678250312805\n",
      "Training Loss: 0.7650847434997559\n",
      "Training Loss: 0.4799058139324188\n",
      "Training Loss: 0.4128570258617401\n",
      "Training Loss: 0.6554807424545288\n",
      "Training Loss: 0.44667258858680725\n",
      "Training Loss: 0.40499716997146606\n",
      "Training Loss: 0.35249942541122437\n",
      "Training Loss: 0.44613006711006165\n",
      "Training Loss: 0.46554267406463623\n",
      "Training Loss: 0.5252923369407654\n",
      "Training Loss: 0.5274717807769775\n",
      "Training Loss: 0.4868505895137787\n",
      "Training Loss: 0.50260329246521\n",
      "Training Loss: 0.4718700051307678\n",
      "Training Loss: 0.4991183578968048\n",
      "Training Loss: 0.5104172825813293\n",
      "Training Loss: 0.589040219783783\n",
      "Test Accuracy: 0.8543689250946045 ---- Test Loss: 0.41957488656044006\n",
      "Epoch time: 5.882020711898804 seconds\n",
      "###### Epoch 5 ######\n",
      "Training Loss: 0.46453139185905457\n",
      "Training Loss: 0.4355372488498688\n",
      "Training Loss: 0.4135398864746094\n",
      "Training Loss: 0.3633357882499695\n",
      "Training Loss: 0.41236552596092224\n",
      "Training Loss: 0.659769594669342\n",
      "Training Loss: 0.35710006952285767\n",
      "Training Loss: 0.3174457252025604\n",
      "Training Loss: 0.4423680901527405\n",
      "Training Loss: 0.5145745873451233\n",
      "Training Loss: 0.32646644115448\n",
      "Training Loss: 0.64598548412323\n",
      "Training Loss: 0.43350037932395935\n",
      "Training Loss: 0.5083714723587036\n",
      "Training Loss: 0.45774880051612854\n",
      "Training Loss: 0.43154633045196533\n",
      "Training Loss: 0.5137048959732056\n",
      "Training Loss: 0.33809542655944824\n",
      "Test Accuracy: 0.8592233061790466 ---- Test Loss: 0.5134309530258179\n",
      "Epoch time: 5.846908330917358 seconds\n",
      "###### Epoch 6 ######\n",
      "Training Loss: 0.34189724922180176\n",
      "Training Loss: 0.4038549065589905\n",
      "Training Loss: 0.2963193655014038\n",
      "Training Loss: 0.27634790539741516\n",
      "Training Loss: 0.41684699058532715\n",
      "Training Loss: 0.5801641941070557\n",
      "Training Loss: 0.2957679033279419\n",
      "Training Loss: 0.4366742968559265\n",
      "Training Loss: 0.38000789284706116\n",
      "Training Loss: 0.3600737452507019\n",
      "Training Loss: 0.3209071755409241\n",
      "Training Loss: 0.39228004217147827\n",
      "Training Loss: 0.2736945152282715\n",
      "Training Loss: 0.2630924582481384\n",
      "Training Loss: 0.32664036750793457\n",
      "Training Loss: 0.31900349259376526\n",
      "Training Loss: 0.27410000562667847\n",
      "Training Loss: 0.37959355115890503\n",
      "Test Accuracy: 0.8640776872634888 ---- Test Loss: 0.43119296431541443\n",
      "Epoch time: 5.850156784057617 seconds\n",
      "###### Epoch 7 ######\n",
      "Training Loss: 0.3208172917366028\n",
      "Training Loss: 0.3642367124557495\n",
      "Training Loss: 0.44979655742645264\n",
      "Training Loss: 0.430520236492157\n",
      "Training Loss: 0.36476871371269226\n",
      "Training Loss: 0.2779783606529236\n",
      "Training Loss: 0.21650873124599457\n",
      "Training Loss: 0.2670459449291229\n",
      "Training Loss: 0.42360493540763855\n",
      "Training Loss: 0.2428150624036789\n",
      "Training Loss: 0.23623201251029968\n",
      "Training Loss: 0.3534877896308899\n",
      "Training Loss: 0.25304219126701355\n",
      "Training Loss: 0.2560875415802002\n",
      "Training Loss: 0.3599075675010681\n",
      "Training Loss: 0.1833043098449707\n",
      "Training Loss: 0.3472256064414978\n",
      "Training Loss: 0.22859036922454834\n",
      "Test Accuracy: 0.893203854560852 ---- Test Loss: 0.33915406465530396\n",
      "Epoch time: 5.958867788314819 seconds\n",
      "###### Epoch 8 ######\n",
      "Training Loss: 0.33038002252578735\n",
      "Training Loss: 0.3073849678039551\n",
      "Training Loss: 0.45510178804397583\n",
      "Training Loss: 0.40073055028915405\n",
      "Training Loss: 0.3681276738643646\n",
      "Training Loss: 0.23939105868339539\n",
      "Training Loss: 0.21396741271018982\n",
      "Training Loss: 0.1877088099718094\n",
      "Training Loss: 0.26776227355003357\n",
      "Training Loss: 0.19146423041820526\n",
      "Training Loss: 0.300660640001297\n",
      "Training Loss: 0.43717890977859497\n",
      "Training Loss: 0.22219444811344147\n",
      "Training Loss: 0.18002675473690033\n",
      "Training Loss: 0.2041117250919342\n",
      "Training Loss: 0.26864007115364075\n",
      "Training Loss: 0.40078431367874146\n",
      "Training Loss: 0.3288863003253937\n",
      "Test Accuracy: 0.8495145440101624 ---- Test Loss: 0.4213676154613495\n",
      "Epoch time: 5.853424787521362 seconds\n",
      "###### Epoch 9 ######\n",
      "Training Loss: 0.3164655864238739\n",
      "Training Loss: 0.20977886021137238\n",
      "Training Loss: 0.23635131120681763\n",
      "Training Loss: 0.2724141776561737\n",
      "Training Loss: 0.19074080884456635\n",
      "Training Loss: 0.1600462943315506\n",
      "Training Loss: 0.24316105246543884\n",
      "Training Loss: 0.2971325218677521\n",
      "Training Loss: 0.34376585483551025\n",
      "Training Loss: 0.457447350025177\n",
      "Training Loss: 0.3791305124759674\n",
      "Training Loss: 0.2970021963119507\n",
      "Training Loss: 0.27642306685447693\n",
      "Training Loss: 0.18651267886161804\n",
      "Training Loss: 0.18528850376605988\n",
      "Training Loss: 0.3107711374759674\n",
      "Training Loss: 0.18739965558052063\n",
      "Training Loss: 0.192425936460495\n",
      "Test Accuracy: 0.893203854560852 ---- Test Loss: 0.2845126688480377\n",
      "Epoch time: 5.868142366409302 seconds\n",
      "###### Epoch 10 ######\n",
      "Training Loss: 0.1953914612531662\n",
      "Training Loss: 0.28222987055778503\n",
      "Training Loss: 0.34485092759132385\n",
      "Training Loss: 0.16309450566768646\n",
      "Training Loss: 0.2869418263435364\n",
      "Training Loss: 0.4220205247402191\n",
      "Training Loss: 0.19286563992500305\n",
      "Training Loss: 0.3071393072605133\n",
      "Training Loss: 0.189231738448143\n",
      "Training Loss: 0.2761076092720032\n",
      "Training Loss: 0.25222674012184143\n",
      "Training Loss: 0.20018808543682098\n",
      "Training Loss: 0.40898242592811584\n",
      "Training Loss: 0.3363295793533325\n",
      "Training Loss: 0.2477409392595291\n",
      "Training Loss: 0.3631778061389923\n",
      "Training Loss: 0.42437389492988586\n",
      "Training Loss: 0.23048236966133118\n",
      "Test Accuracy: 0.8980582356452942 ---- Test Loss: 0.34925660490989685\n",
      "Epoch time: 5.8434388637542725 seconds\n",
      "###### Epoch 11 ######\n",
      "Training Loss: 0.38077181577682495\n",
      "Training Loss: 0.3901641368865967\n",
      "Training Loss: 0.2504766583442688\n",
      "Training Loss: 0.4013684093952179\n",
      "Training Loss: 0.2802284359931946\n",
      "Training Loss: 0.32867392897605896\n",
      "Training Loss: 0.22091029584407806\n",
      "Training Loss: 0.44415736198425293\n",
      "Training Loss: 0.2745314836502075\n",
      "Training Loss: 0.12730631232261658\n",
      "Training Loss: 0.23443235456943512\n",
      "Training Loss: 0.1329813003540039\n",
      "Training Loss: 0.25691214203834534\n",
      "Training Loss: 0.21391671895980835\n",
      "Training Loss: 0.2414943277835846\n",
      "Training Loss: 0.18359249830245972\n",
      "Training Loss: 0.17660216987133026\n",
      "Training Loss: 0.13568851351737976\n",
      "Test Accuracy: 0.9077669978141785 ---- Test Loss: 0.28186720609664917\n",
      "Epoch time: 6.808928728103638 seconds\n",
      "###### Epoch 12 ######\n",
      "Training Loss: 0.1420949399471283\n",
      "Training Loss: 0.20639461278915405\n",
      "Training Loss: 0.09972231090068817\n",
      "Training Loss: 0.19814357161521912\n",
      "Training Loss: 0.14429403841495514\n",
      "Training Loss: 0.18875427544116974\n",
      "Training Loss: 0.23150844871997833\n",
      "Training Loss: 0.120254285633564\n",
      "Training Loss: 0.20372416079044342\n",
      "Training Loss: 0.19621379673480988\n",
      "Training Loss: 0.17025209963321686\n",
      "Training Loss: 0.14040295779705048\n",
      "Training Loss: 0.419656366109848\n",
      "Training Loss: 0.29559963941574097\n",
      "Training Loss: 0.185087189078331\n",
      "Training Loss: 0.21053577959537506\n",
      "Training Loss: 0.2360219806432724\n",
      "Training Loss: 0.27215588092803955\n",
      "Test Accuracy: 0.9029126167297363 ---- Test Loss: 0.22971919178962708\n",
      "Epoch time: 5.876978158950806 seconds\n",
      "###### Epoch 13 ######\n",
      "Training Loss: 0.1675647497177124\n",
      "Training Loss: 0.1608743816614151\n",
      "Training Loss: 0.1724928468465805\n",
      "Training Loss: 0.24182967841625214\n",
      "Training Loss: 0.3326497972011566\n",
      "Training Loss: 0.113066665828228\n",
      "Training Loss: 0.12683627009391785\n",
      "Training Loss: 0.13967645168304443\n",
      "Training Loss: 0.19164900481700897\n",
      "Training Loss: 0.0967457965016365\n",
      "Training Loss: 0.09024538099765778\n",
      "Training Loss: 0.1854117065668106\n",
      "Training Loss: 0.17085601389408112\n",
      "Training Loss: 0.12045825272798538\n",
      "Training Loss: 0.2096935510635376\n",
      "Training Loss: 0.19940157234668732\n",
      "Training Loss: 0.1310395747423172\n",
      "Training Loss: 0.14063820242881775\n",
      "Test Accuracy: 0.9271844625473022 ---- Test Loss: 0.20901057124137878\n",
      "Epoch time: 5.8542094230651855 seconds\n",
      "###### Epoch 14 ######\n",
      "Training Loss: 0.1525113731622696\n",
      "Training Loss: 0.14685474336147308\n",
      "Training Loss: 0.1760241687297821\n",
      "Training Loss: 0.18410421907901764\n",
      "Training Loss: 0.08734605461359024\n",
      "Training Loss: 0.18986155092716217\n",
      "Training Loss: 0.1312183439731598\n",
      "Training Loss: 0.2163320779800415\n",
      "Training Loss: 0.19207243621349335\n",
      "Training Loss: 0.11200904101133347\n",
      "Training Loss: 0.07463409751653671\n",
      "Training Loss: 0.21084186434745789\n",
      "Training Loss: 0.16174261271953583\n",
      "Training Loss: 0.12462355941534042\n",
      "Training Loss: 0.2089511901140213\n",
      "Training Loss: 0.15636344254016876\n",
      "Training Loss: 0.14977429807186127\n",
      "Training Loss: 0.24700526893138885\n",
      "Test Accuracy: 0.893203854560852 ---- Test Loss: 0.2774520516395569\n",
      "Epoch time: 5.880626916885376 seconds\n",
      "###### Epoch 15 ######\n",
      "Training Loss: 0.23611396551132202\n",
      "Training Loss: 0.19995687901973724\n",
      "Training Loss: 0.175742968916893\n",
      "Training Loss: 0.11609577387571335\n",
      "Training Loss: 0.10100167244672775\n",
      "Training Loss: 0.19865673780441284\n",
      "Training Loss: 0.20689713954925537\n",
      "Training Loss: 0.20251548290252686\n",
      "Training Loss: 0.1759987324476242\n",
      "Training Loss: 0.1919889599084854\n",
      "Training Loss: 0.10885016620159149\n",
      "Training Loss: 0.11288278549909592\n",
      "Training Loss: 0.23899371922016144\n",
      "Training Loss: 0.09017674624919891\n",
      "Training Loss: 0.15304750204086304\n",
      "Training Loss: 0.20553500950336456\n",
      "Training Loss: 0.12249918282032013\n",
      "Training Loss: 0.06757135689258575\n",
      "Test Accuracy: 0.9271844625473022 ---- Test Loss: 0.17980170249938965\n",
      "Epoch time: 5.847326993942261 seconds\n",
      "###### Epoch 16 ######\n",
      "Training Loss: 0.08239728212356567\n",
      "Training Loss: 0.07322914153337479\n",
      "Training Loss: 0.11122890561819077\n",
      "Training Loss: 0.12082581222057343\n",
      "Training Loss: 0.07986824959516525\n",
      "Training Loss: 0.1151224672794342\n",
      "Training Loss: 0.07679568231105804\n",
      "Training Loss: 0.1343340426683426\n",
      "Training Loss: 0.07821798324584961\n",
      "Training Loss: 0.11417149752378464\n",
      "Training Loss: 0.15000063180923462\n",
      "Training Loss: 0.11037009954452515\n",
      "Training Loss: 0.12275511026382446\n",
      "Training Loss: 0.05281263217329979\n",
      "Training Loss: 0.14357830584049225\n",
      "Training Loss: 0.21317343413829803\n",
      "Training Loss: 0.11567480862140656\n",
      "Training Loss: 0.15015961229801178\n",
      "Test Accuracy: 0.9368932247161865 ---- Test Loss: 0.1512339562177658\n",
      "Epoch time: 5.847647666931152 seconds\n",
      "###### Epoch 17 ######\n",
      "Training Loss: 0.12520088255405426\n",
      "Training Loss: 0.08402119576931\n",
      "Training Loss: 0.1365901231765747\n",
      "Training Loss: 0.06623086333274841\n",
      "Training Loss: 0.1523195058107376\n",
      "Training Loss: 0.17434102296829224\n",
      "Training Loss: 0.08533528447151184\n",
      "Training Loss: 0.17355689406394958\n",
      "Training Loss: 0.1237487867474556\n",
      "Training Loss: 0.08532685041427612\n",
      "Training Loss: 0.07988140732049942\n",
      "Training Loss: 0.11772935092449188\n",
      "Training Loss: 0.06394407153129578\n",
      "Training Loss: 0.07471282035112381\n",
      "Training Loss: 0.1002151295542717\n",
      "Training Loss: 0.12869320809841156\n",
      "Training Loss: 0.16282983124256134\n",
      "Training Loss: 0.18093341588974\n",
      "Test Accuracy: 0.946601927280426 ---- Test Loss: 0.18094542622566223\n",
      "Epoch time: 5.8550941944122314 seconds\n",
      "###### Epoch 18 ######\n",
      "Training Loss: 0.10478856414556503\n",
      "Training Loss: 0.11561224609613419\n",
      "Training Loss: 0.13012073934078217\n",
      "Training Loss: 0.05514046177268028\n",
      "Training Loss: 0.07216360419988632\n",
      "Training Loss: 0.07697582989931107\n",
      "Training Loss: 0.08309660851955414\n",
      "Training Loss: 0.07583015412092209\n",
      "Training Loss: 0.1014922559261322\n",
      "Training Loss: 0.15763035416603088\n",
      "Training Loss: 0.07132980972528458\n",
      "Training Loss: 0.09142142534255981\n",
      "Training Loss: 0.08200005441904068\n",
      "Training Loss: 0.1072181686758995\n",
      "Training Loss: 0.11395163834095001\n",
      "Training Loss: 0.054683782160282135\n",
      "Training Loss: 0.09972555935382843\n",
      "Training Loss: 0.12981118261814117\n",
      "Test Accuracy: 0.9514563083648682 ---- Test Loss: 0.13114631175994873\n",
      "Epoch time: 6.777456283569336 seconds\n",
      "###### Epoch 19 ######\n",
      "Training Loss: 0.07564616203308105\n",
      "Training Loss: 0.05459461733698845\n",
      "Training Loss: 0.09107328206300735\n",
      "Training Loss: 0.07898213714361191\n",
      "Training Loss: 0.05884336307644844\n",
      "Training Loss: 0.10652574896812439\n",
      "Training Loss: 0.09956274181604385\n",
      "Training Loss: 0.13608825206756592\n",
      "Training Loss: 0.03763406351208687\n",
      "Training Loss: 0.06091022491455078\n",
      "Training Loss: 0.06080048531293869\n",
      "Training Loss: 0.058387428522109985\n",
      "Training Loss: 0.06801244616508484\n",
      "Training Loss: 0.07069575041532516\n",
      "Training Loss: 0.03834785148501396\n",
      "Training Loss: 0.1153009906411171\n",
      "Training Loss: 0.12178228050470352\n",
      "Training Loss: 0.14375275373458862\n",
      "Test Accuracy: 0.9660193920135498 ---- Test Loss: 0.10662543028593063\n",
      "Epoch time: 5.871561527252197 seconds\n",
      "###### Epoch 20 ######\n",
      "Training Loss: 0.07700064778327942\n",
      "Training Loss: 0.12629050016403198\n",
      "Training Loss: 0.040676865726709366\n",
      "Training Loss: 0.06804260611534119\n",
      "Training Loss: 0.12330705672502518\n",
      "Training Loss: 0.07185123860836029\n",
      "Training Loss: 0.1039421334862709\n",
      "Training Loss: 0.05385751649737358\n",
      "Training Loss: 0.07006638497114182\n",
      "Training Loss: 0.04365648701786995\n",
      "Training Loss: 0.12008456140756607\n",
      "Training Loss: 0.06271519511938095\n",
      "Training Loss: 0.05946480110287666\n",
      "Training Loss: 0.0630829930305481\n",
      "Training Loss: 0.10345020890235901\n",
      "Training Loss: 0.11378508806228638\n",
      "Training Loss: 0.22322319447994232\n",
      "Training Loss: 0.11591137945652008\n",
      "Test Accuracy: 0.9660193920135498 ---- Test Loss: 0.10840805619955063\n",
      "Epoch time: 6.849567413330078 seconds\n",
      "###### Epoch 21 ######\n",
      "Training Loss: 0.04766501858830452\n",
      "Training Loss: 0.13260991871356964\n",
      "Training Loss: 0.053574301302433014\n",
      "Training Loss: 0.09375689178705215\n",
      "Training Loss: 0.05762789770960808\n",
      "Training Loss: 0.08493293076753616\n",
      "Training Loss: 0.07620376348495483\n",
      "Training Loss: 0.07939615845680237\n",
      "Training Loss: 0.05698176473379135\n",
      "Training Loss: 0.09921076148748398\n",
      "Training Loss: 0.15843406319618225\n",
      "Training Loss: 0.11018725484609604\n",
      "Training Loss: 0.12934786081314087\n",
      "Training Loss: 0.2121339589357376\n",
      "Training Loss: 0.16193048655986786\n",
      "Training Loss: 0.09987102448940277\n",
      "Training Loss: 0.07884249091148376\n",
      "Training Loss: 0.05264021456241608\n",
      "Test Accuracy: 0.9611650705337524 ---- Test Loss: 0.10093849152326584\n",
      "Epoch time: 5.875982046127319 seconds\n",
      "###### Epoch 22 ######\n",
      "Training Loss: 0.07108510285615921\n",
      "Training Loss: 0.14293326437473297\n",
      "Training Loss: 0.0921541154384613\n",
      "Training Loss: 0.09129920601844788\n",
      "Training Loss: 0.1423642635345459\n",
      "Training Loss: 0.13695257902145386\n",
      "Training Loss: 0.04293845221400261\n",
      "Training Loss: 0.18598759174346924\n",
      "Training Loss: 0.2070164531469345\n",
      "Training Loss: 0.03863091394305229\n",
      "Training Loss: 0.21237251162528992\n",
      "Training Loss: 0.11275999993085861\n",
      "Training Loss: 0.08233330398797989\n",
      "Training Loss: 0.07316146790981293\n",
      "Training Loss: 0.1818924844264984\n",
      "Training Loss: 0.08461146056652069\n",
      "Training Loss: 0.1519610732793808\n",
      "Training Loss: 0.18312983214855194\n",
      "Test Accuracy: 0.9271844625473022 ---- Test Loss: 0.18528196215629578\n",
      "Epoch time: 5.889415264129639 seconds\n",
      "###### Epoch 23 ######\n",
      "Training Loss: 0.08926615118980408\n",
      "Training Loss: 0.06116078421473503\n",
      "Training Loss: 0.13097555935382843\n",
      "Training Loss: 0.36043450236320496\n",
      "Training Loss: 0.245806023478508\n",
      "Training Loss: 0.1735602617263794\n",
      "Training Loss: 0.09640704840421677\n",
      "Training Loss: 0.09063464403152466\n",
      "Training Loss: 0.21757760643959045\n",
      "Training Loss: 0.14286914467811584\n",
      "Training Loss: 0.07698923349380493\n",
      "Training Loss: 0.18076974153518677\n",
      "Training Loss: 0.10182803124189377\n",
      "Training Loss: 0.07913731783628464\n",
      "Training Loss: 0.12442322820425034\n",
      "Training Loss: 0.09545865654945374\n",
      "Training Loss: 0.03933766484260559\n",
      "Training Loss: 0.1019522175192833\n",
      "Test Accuracy: 0.946601927280426 ---- Test Loss: 0.14388257265090942\n",
      "Epoch time: 5.87204384803772 seconds\n",
      "###### Epoch 24 ######\n",
      "Training Loss: 0.12937350571155548\n",
      "Training Loss: 0.08356250077486038\n",
      "Training Loss: 0.09471005201339722\n",
      "Training Loss: 0.08440246433019638\n",
      "Training Loss: 0.05692615360021591\n",
      "Training Loss: 0.13514657318592072\n",
      "Training Loss: 0.0641307458281517\n",
      "Training Loss: 0.023649385198950768\n",
      "Training Loss: 0.09650224447250366\n",
      "Training Loss: 0.1410941630601883\n",
      "Training Loss: 0.20848660171031952\n",
      "Training Loss: 0.09139298647642136\n",
      "Training Loss: 0.13802851736545563\n",
      "Training Loss: 0.10516771674156189\n",
      "Training Loss: 0.049705762416124344\n",
      "Training Loss: 0.06209852546453476\n",
      "Training Loss: 0.13160577416419983\n",
      "Training Loss: 0.07435891032218933\n",
      "Test Accuracy: 0.9757281541824341 ---- Test Loss: 0.12618166208267212\n",
      "Epoch time: 5.877124547958374 seconds\n",
      "###### Epoch 25 ######\n",
      "Training Loss: 0.10784919559955597\n",
      "Training Loss: 0.04830828681588173\n",
      "Training Loss: 0.07757056504487991\n",
      "Training Loss: 0.029196662828326225\n",
      "Training Loss: 0.06704716384410858\n",
      "Training Loss: 0.08903662860393524\n",
      "Training Loss: 0.06245604529976845\n",
      "Training Loss: 0.03159468621015549\n",
      "Training Loss: 0.07366567850112915\n",
      "Training Loss: 0.06647379696369171\n",
      "Training Loss: 0.025714362040162086\n",
      "Training Loss: 0.07325474917888641\n",
      "Training Loss: 0.06914708018302917\n",
      "Training Loss: 0.02592790313065052\n",
      "Training Loss: 0.04626338183879852\n",
      "Training Loss: 0.06967265903949738\n",
      "Training Loss: 0.04892341047525406\n",
      "Training Loss: 0.042814355343580246\n",
      "Test Accuracy: 0.9805825352668762 ---- Test Loss: 0.05462106317281723\n",
      "Epoch time: 5.186525344848633 seconds\n",
      "###### Epoch 26 ######\n",
      "Training Loss: 0.05978522449731827\n",
      "Training Loss: 0.04317821189761162\n",
      "Training Loss: 0.03827596455812454\n",
      "Training Loss: 0.0486551970243454\n",
      "Training Loss: 0.023692715913057327\n",
      "Training Loss: 0.08864603191614151\n",
      "Training Loss: 0.018513314425945282\n",
      "Training Loss: 0.09194586426019669\n",
      "Training Loss: 0.038174018263816833\n",
      "Training Loss: 0.03770805895328522\n",
      "Training Loss: 0.08728348463773727\n",
      "Training Loss: 0.0272731464356184\n",
      "Training Loss: 0.021476799622178078\n",
      "Training Loss: 0.029890937730669975\n",
      "Training Loss: 0.059435658156871796\n",
      "Training Loss: 0.09578584879636765\n",
      "Training Loss: 0.07075159251689911\n",
      "Training Loss: 0.05696805566549301\n",
      "Test Accuracy: 0.9611650705337524 ---- Test Loss: 0.10926076024770737\n",
      "Epoch time: 5.882258176803589 seconds\n",
      "###### Epoch 27 ######\n",
      "Training Loss: 0.03322222828865051\n",
      "Training Loss: 0.039333242923021317\n",
      "Training Loss: 0.02204608917236328\n",
      "Training Loss: 0.06121634319424629\n",
      "Training Loss: 0.05285409837961197\n",
      "Training Loss: 0.04881499707698822\n",
      "Training Loss: 0.013177904300391674\n",
      "Training Loss: 0.018722251057624817\n",
      "Training Loss: 0.030334044247865677\n",
      "Training Loss: 0.026324260979890823\n",
      "Training Loss: 0.04745759814977646\n",
      "Training Loss: 0.013743838295340538\n",
      "Training Loss: 0.042162977159023285\n",
      "Training Loss: 0.03306408226490021\n",
      "Training Loss: 0.046173833310604095\n",
      "Training Loss: 0.053196027874946594\n",
      "Training Loss: 0.01803397387266159\n",
      "Training Loss: 0.05562414601445198\n",
      "Test Accuracy: 0.9563106894493103 ---- Test Loss: 0.093485526740551\n",
      "Epoch time: 5.8524463176727295 seconds\n",
      "###### Epoch 28 ######\n",
      "Training Loss: 0.050456706434488297\n",
      "Training Loss: 0.016101090237498283\n",
      "Training Loss: 0.056308332830667496\n",
      "Training Loss: 0.024410514160990715\n",
      "Training Loss: 0.022032305598258972\n",
      "Training Loss: 0.04323533549904823\n",
      "Training Loss: 0.03601301833987236\n",
      "Training Loss: 0.056675124913454056\n",
      "Training Loss: 0.01751335710287094\n",
      "Training Loss: 0.03486413508653641\n",
      "Training Loss: 0.02757100574672222\n",
      "Training Loss: 0.06790826469659805\n",
      "Training Loss: 0.0856538936495781\n",
      "Training Loss: 0.034039147198200226\n",
      "Training Loss: 0.05350063368678093\n",
      "Training Loss: 0.009636708535254002\n",
      "Training Loss: 0.016116786748170853\n",
      "Training Loss: 0.08533560484647751\n",
      "Test Accuracy: 0.9854369163513184 ---- Test Loss: 0.06463215500116348\n",
      "Epoch time: 5.880132675170898 seconds\n",
      "###### Epoch 29 ######\n",
      "Training Loss: 0.04452214762568474\n",
      "Training Loss: 0.023362191393971443\n",
      "Training Loss: 0.04467187076807022\n",
      "Training Loss: 0.05732354521751404\n",
      "Training Loss: 0.01943804882466793\n",
      "Training Loss: 0.07132925093173981\n",
      "Training Loss: 0.03375381603837013\n",
      "Training Loss: 0.02853759378194809\n",
      "Training Loss: 0.11434077471494675\n",
      "Training Loss: 0.03314292058348656\n",
      "Training Loss: 0.042352400720119476\n",
      "Training Loss: 0.02977687306702137\n",
      "Training Loss: 0.07125185430049896\n",
      "Training Loss: 0.031690437346696854\n",
      "Training Loss: 0.04870457574725151\n",
      "Training Loss: 0.0513661652803421\n",
      "Training Loss: 0.12488611042499542\n",
      "Training Loss: 0.015624243766069412\n",
      "Test Accuracy: 0.9854369163513184 ---- Test Loss: 0.06645440310239792\n",
      "Epoch time: 5.890428304672241 seconds\n",
      "###### Epoch 30 ######\n",
      "Training Loss: 0.0450599379837513\n",
      "Training Loss: 0.010516886599361897\n",
      "Training Loss: 0.05820022523403168\n",
      "Training Loss: 0.06571876257658005\n",
      "Training Loss: 0.025695620104670525\n",
      "Training Loss: 0.0237088855355978\n",
      "Training Loss: 0.07240889966487885\n",
      "Training Loss: 0.052386198192834854\n",
      "Training Loss: 0.134996697306633\n",
      "Training Loss: 0.05441782996058464\n",
      "Training Loss: 0.021094398573040962\n",
      "Training Loss: 0.034058816730976105\n",
      "Training Loss: 0.20462749898433685\n",
      "Training Loss: 0.020160377025604248\n",
      "Training Loss: 0.09101730585098267\n",
      "Training Loss: 0.040527213364839554\n",
      "Training Loss: 0.11136302351951599\n",
      "Training Loss: 0.0314369797706604\n",
      "Test Accuracy: 0.946601927280426 ---- Test Loss: 0.2260172963142395\n",
      "Epoch time: 5.893641471862793 seconds\n"
     ]
    }
   ],
   "source": [
    "from tools.utils import train, test\n",
    "\n",
    "losses, test_accs, test_losses, epsilons, alphas, epoch_times = train(BATCH_SIZE, EPOCHS, DELTA, \n",
    "                                                                      remote_model, remote_torch,\n",
    "                                                                      optim, loss_function, \n",
    "                                                                      train_data_ptr, train_labels_ptr, \n",
    "                                                                      test_data_ptr, test_labels_ptr, \n",
    "                                                                      [1, 64, 64], device, privacy_engine_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9521ae8-ba3b-4697-bc11-4247f07d2b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9013605442176871 ---- Validation Loss: 0.3175201714038849\n"
     ]
    }
   ],
   "source": [
    "from tools import datasets\n",
    "# TODO!: Use best model for validation\n",
    "# Sadly very redundant since remotly tracking best model is not easily possible and therefore just last model is used for validation\n",
    "# Evalutating the model locally with the validation data\n",
    "eval_model = remote_model.get(request_block=True, reason=\"Needed for local evaluation!\")\n",
    "eval_model.cuda(torch.device('cuda:0'))\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Higher sample_size here as on DO side will ensure that it is actually data that is not in train or test set!\n",
    "_, _, val_ds = datasets.Loader.load_MedNIST(sample_size=0.1, test_size=0.1, val_size=0.05)\n",
    "val_data, val_labels = val_ds.as_tensor()\n",
    "\n",
    "val_acc, val_loss = test(eval_model, loss_function, torch, val_data, val_labels, torch.device('cuda:0'))\n",
    "\n",
    "print(f'Validation Accuracy: {val_acc} ---- Validation Loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f07ae45-0590-41e0-a203-1e3c1151307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking all interesting variables and results in .csv file\n",
    "if TRACKING:\n",
    "    d = {\n",
    "        'model': MODEL,\n",
    "        'dataset': DATASET,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'epochs': EPOCHS,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'train_sample_size': SAMPLE_SIZE,\n",
    "        'test_sample_size': len(test_data_ptr),\n",
    "        'val_sample_size': len(val_data),\n",
    "        'delta': DELTA,\n",
    "        'noise_multiplier': NOISE_MULTIPLIER,\n",
    "        'max_grad_norm': MAX_GRAD_NORM,\n",
    "        'dp_used': DP,\n",
    "        'epsilons': epsilons,\n",
    "        'alphas': alphas,\n",
    "        'train_losses': losses,\n",
    "        'test_accs': test_accs,\n",
    "        'test_losses': test_losses,\n",
    "        'val_acc': val_acc,\n",
    "        'val_loss': val_loss,\n",
    "        'epoch_times': epoch_times\n",
    "    }      \n",
    "    df = pd.read_csv('./Results/1DO-1DS.csv')\n",
    "    df = df.append(d, ignore_index=True)\n",
    "    df.to_csv('./Results/1DO-1DS.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
